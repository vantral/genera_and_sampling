{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fa6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import bibtexparser\n",
    "import re\n",
    "\n",
    "import configparser\n",
    "config = configparser.RawConfigParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6d77b",
   "metadata": {},
   "source": [
    "Collecting all paths to .ini files from glottolog and converting them into Path objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fec8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1454b43e6894b2bbdc10d0cb13586c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53503 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = []\n",
    "\n",
    "for path in tqdm(glob.glob('glottolog/languoids/tree/**/*', recursive=True)):\n",
    "    if path.endswith('.ini'):\n",
    "        paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5215fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [Path(path) for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558bbf65",
   "metadata": {},
   "source": [
    "Parsing .ini files into dict with information on a language including their glottocode, path to the corresponding .ini file, level, sources, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5271722f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c2566924f1447d83acaf7ead4cfb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26737 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mds = []\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    config = configparser.RawConfigParser()\n",
    "    config.read(path, encoding='utf8')\n",
    "    md = {s:dict(config[s].items()) for s in config.sections()}\n",
    "    dct = {'glottocode': path.parts[-2], 'path': Path(*path.parts[2:-1]).as_posix()}\n",
    "    core = md['core'].copy()\n",
    "    dct.update(core)\n",
    "#     print(dct)\n",
    "    del md['core']\n",
    "    dct['other'] = md\n",
    "    mds.append(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e53d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glottocode': 'abin1243',\n",
       " 'path': 'tree/abin1243',\n",
       " 'name': 'Abinomn',\n",
       " 'hid': 'bsa',\n",
       " 'level': 'language',\n",
       " 'iso639-3': 'bsa',\n",
       " 'latitude': '-2.92281',\n",
       " 'longitude': '138.891',\n",
       " 'macroareas': '\\nPapunesia',\n",
       " 'countries': '\\nID',\n",
       " 'links': '\\n[Abinomn](https://endangeredlanguages.com/lang/1763)\\nhttps://en.wikipedia.org/wiki/Abinomn_language\\nhttps://www.wikidata.org/entity/Q56648',\n",
       " 'other': {'sources': {'glottolog': '\\n**elcat:6f91926917d8609bd798174c58ad27cf**\\n**hh:e:Lagerberg:Moegip**\\n**hh:h:SilzerClouse:Index**\\n**hh:h:SilzerHeikkinen:Irian**\\n**hh:hv:Foley:Northwest-New-Guinea**\\n**hh:hvtyp:DonohueMusgrave:Melanesia**\\n**hh:w:Fiwei:Abinomn**'},\n",
       "  'altnames': {'multitree': '\\n\"Baso\"\\nAbinomn\\nAvinomen\\nFoja\\nFoya',\n",
       "   'lexvo': '\\nAbinomn [en]\\nAbinomn language [en]\\nAbinomneg [br]\\nLingua abinomn [gl]\\nLlingua Abinomn [ast]',\n",
       "   'hhbib_lgcode': '\\nBaso',\n",
       "   'elcat': '\\n\"Baso\"\\nAbinomn\\nAvinomen\\nFoja\\nFoya'},\n",
       "  'triggers': {'lgcode': '\\nmacrohistory\\nmoegip'},\n",
       "  'identifier': {'multitree': 'bsa', 'endangeredlanguages': '1763'},\n",
       "  'classification': {'familyrefs': '\\n**hh:h:SilzerClouse:Index**\\n**hh:hvtyp:DonohueMusgrave:Melanesia**'},\n",
       "  'endangerment': {'status': 'nearly extinct',\n",
       "   'source': 'ElCat',\n",
       "   'date': '2023-07-06T16:07:13',\n",
       "   'comment': 'Abinomn (1763-bsa) = Critically Endangered (40 percent certain, based on the evidence available) (Speakers are shifting to the neighbouring Mander language, which also has few native speakers. The number of Foya speakers is likely to be considerably less than fifty. It has been seriously endangered before, but is now more likely to be moribund.) [Wurm 2007](elcat:e60e81c4cbe5171cd654662d9887aec2)'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049ea52",
   "metadata": {},
   "source": [
    "Keeping only languages (excluding dialects and families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e71217",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data = pd.DataFrame(mds)\n",
    "raw_languages_data = md_data[md_data.level == 'language'].copy()\n",
    "language_list = raw_languages_data.glottocode.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7493f",
   "metadata": {},
   "source": [
    "Extracting literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed1f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = raw_languages_data.other.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f57e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [x['sources']['glottolog'].strip('\\n *') if 'sources' in x else '' for x in sources]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a76f15",
   "metadata": {},
   "source": [
    "Parsing all bibtex files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafbfa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27687347c6d54f9aa31360424257415a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parsing of `@incollection` block (line 690011) aborted on line 690024  due to syntactical error in bibtex:\n",
      " Unexpected block start: `@incollection`. Was still looking for field-value closing `,` or `}` \n",
      "WARNING:root:Unknown block type <class 'bibtexparser.model.ParsingFailedBlock'>\n",
      "WARNING:root:Unknown block type <class 'bibtexparser.model.DuplicateBlockKeyBlock'>\n",
      "WARNING:root:Parsing of `@incollection` block (line 88598) aborted on line 88598  due to syntactical error in bibtex:\n",
      " Expected comma after entry key, but found \"\n",
      "WARNING:root:Parsing of `@article` block (line 244518) aborted on line 244518  due to syntactical error in bibtex:\n",
      " Expected comma after entry key, but found \"\n",
      "WARNING:root:Parsing of `@book` block (line 391139) aborted on line 391139  due to syntactical error in bibtex:\n",
      " Expected comma after entry key, but found \"\n",
      "WARNING:root:Unknown block type <class 'bibtexparser.model.ParsingFailedBlock'>\n",
      "WARNING:root:Unknown block type <class 'bibtexparser.model.ParsingFailedBlock'>\n",
      "WARNING:root:Unknown block type <class 'bibtexparser.model.ParsingFailedBlock'>\n"
     ]
    }
   ],
   "source": [
    "libraries = {}\n",
    "for file in tqdm(Path('glottolog/references/bibtex/').iterdir()):\n",
    "    libraries[file.stem] = bibtexparser.parse_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d0ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entry(library_name, key, libraries):\n",
    "    \"\"\"\n",
    "    This function receives library name, dict of all libraries and the key that\n",
    "    must be found\n",
    "    \"\"\"\n",
    "    for entry in libraries[library_name].entries:\n",
    "        if entry.key == key:\n",
    "            return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd233532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pages_of_grammar(entry):\n",
    "    \"\"\"\n",
    "    Receives entry and return string describing pages of the grammar\n",
    "    \"\"\"\n",
    "    pages = None\n",
    "    for field in entry.fields:\n",
    "        if field.key == 'pages':\n",
    "            pages = field.value\n",
    "        if field.key == 'hhtype':\n",
    "            if 'grammar' not in field.value:\n",
    "                return None\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a75a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2int(numeric):\n",
    "    \"\"\"\n",
    "    This function receives a string with numeric describing the number of pages\n",
    "    and tries to convert it into integer\n",
    "    \"\"\"\n",
    "    numeric = numeric.strip()\n",
    "    if not numeric:\n",
    "        return 0\n",
    "    if numeric.isdigit():\n",
    "        return int(numeric)\n",
    "    if '-' in numeric:\n",
    "        start, end = numeric.split('-', 1)\n",
    "        return string2int(end) - string2int(start) + 1\n",
    "    if '+' in numeric:\n",
    "        parts_plus = numeric.split('+')\n",
    "        return sum([string2int(x) for x in parts_plus])\n",
    "    rom_val = {'i': 1, 'v': 5, 'x': 10, 'l': 50, 'c': 100, 'd': 500, 'm': 1000}\n",
    "    int_val = 0\n",
    "    for i in range(len(numeric)):\n",
    "        if i > 0 and rom_val[numeric[i]] > rom_val[numeric[i - 1]]:\n",
    "            int_val += rom_val[numeric[i]] - 2 * rom_val[numeric[i - 1]]\n",
    "        else:\n",
    "            int_val += rom_val[numeric[i]]\n",
    "    return int_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d887b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pages(string_pages: str):\n",
    "    \"\"\"\n",
    "    This function receives a string describing the number of pages\n",
    "    and tries to convert it into integer\n",
    "    \"\"\"\n",
    "    parts_comma = re.split(r'[,;] ?', string_pages)\n",
    "    for i, part in enumerate(parts_comma):\n",
    "        part = part.replace('â€“', '-')\n",
    "        part = re.sub(r'\\(.*?\\)', '', part).strip()\n",
    "        part = re.sub(r'(?:plates?|ff?|S\\.|pp|\\+? ?map|tables|\\?|\\[|\\])', '', part).strip()\n",
    "        parts_comma[i] = string2int(part)\n",
    "    return sum(parts_comma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccd6fb",
   "metadata": {},
   "source": [
    "For each source, I try to convert string describing the pages into the iteger meaning the number of pages. I use only hh database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e51eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e0d2b46fb3496a97183e80599c7072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sources_pages = []\n",
    "for source in tqdm(sources):\n",
    "    n_pages = []\n",
    "    for entry in source.split('**\\n**'):\n",
    "        if not entry:\n",
    "            continue\n",
    "        library, name = entry.split(':', 1)\n",
    "        \n",
    "        if library != 'hh':\n",
    "            continue\n",
    "            \n",
    "        entry = find_entry(library, name, libraries)\n",
    "        pages = find_pages_of_grammar(entry)\n",
    "        \n",
    "        if not pages:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            n_pages.append(count_pages(pages))\n",
    "        except:\n",
    "            if pages:\n",
    "                n_pages.append(pages)\n",
    "    sources_pages.append(n_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4f4b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_languages_data['pages'] = sources_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8d965437",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_languages_data.to_csv('languages_with_pages.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
